{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusiones finales del proyecto NLP\n",
        "\n",
        "## Evaluación del trabajo realizado\n",
        "\n",
        "En este proyecto se abordó el análisis de sentimiento de reseñas de videojuegos con tres enfoques distintos de modelado, evaluando su rendimiento y reflexionando sobre las decisiones de preprocesamiento y modelado.\n",
        "\n",
        "- **Logistic Regression con TF-IDF**: modelo clásico, interpretable y rápido. Alcanzó un accuracy del 78%. Ideal como baseline por su bajo coste y robustez básica. El procentaje es bajo, y estoy seguro que podría mejorar mucho principalmente mejorando el procesamiento de datos, haciendo un estudio más riguroso y permitienedo el uso de negaciones que cambiarn el sentido de la frase. El accuracy parecía ya no poder mejorar al modificar la paramétrica así que estoy seguro que la mejora estaría en el procesamiento.\n",
        "- **Naive Bayes con One-Hot**: eficiente y simple, pero limitado por su incapacidad de captar relaciones contextuales. Accuracy cercano al 77%. Al igual que el punto anterior, creo que la mejora del modelo estararía en la parámetrica y en uso de TF-IDF o similares en vez de one-hot, quice mantenerlo para ver como trabaja y creo que ha sido un acercamiento decente.\n",
        "- **BERT**: enfoque más potente, entrenado con y sin stopwords para contrastar. El mejor rendimiento lo obtuvo **con las stopwords incluidas**, alcanzando un **accuracy del 84.3%** y un **f1-score de 0.66 en la clase negativa**. Demuestra la importancia del contexto completo para modelos de lenguaje profundo. Aun así aun me falta mucho por comprender este modelo, a diferencia de los otros modelos tengo que investigar más para saber como mejorarlo, aun así encuentro claro el uso de estas últimas tecnologías como respuesta a este tipo de problema.\n",
        "\n",
        "## Mejoras futuras con más tiempo\n",
        "\n",
        "1. **Exploración**\n",
        "   - Visualizar la evolución del vocabulario y análisis semántico por clase.\n",
        "   - Incluir análisis de negaciones, ironía, y expresiones idiomáticas.\n",
        "   - Realizar análisis temporal (si se dispone de fechas) para detectar evolución del sentimiento.\n",
        "   - Se que me empeciné a trabajar sobre el modelo desvalanceado, tomando en cuenta que lo limité a 5000 registros pude haberlo balanceado a posta, pero la experiencia me ha mostrado que es raro poder trabajar así. Pero si, en este caso en particular pude haber balanceado para mejorar el resto de pocesos en adelante.\n",
        "\n",
        "2. **Preprocesado**\n",
        "   - Aplicar lematización para reducir la dispersión del vocabulario.\n",
        "   - Implementar reglas específicas para términos del dominio (como \"p2w\", \"op\", \"pvp\", \"p2f\", \"pve\", \"p2play\", etc.).\n",
        "   - Añadir detección de sarcasmo o lenguaje informal con reglas o embeddings adicionales.\n",
        "\n",
        "3. **Modelado clásico**\n",
        "   - Realizar validación cruzada (`StratifiedKFold`) para estimaciones más robustas.\n",
        "   - Incluir modelos adicionales como SVM o XGBoost.\n",
        "   - Hacer un análisis de errores detallado para ver casos mal clasificados y aprender de ellos. (Este se me haría sumamente interesante si tuviera tiempo)\n",
        "   \n",
        "4. **Modelado profundo**\n",
        "   - Probar variantes como DistilBERT o RoBERTa para mayor eficiencia.\n",
        "   - Ajustar hiperparámetros con más epochs o regularización. Creo que este sería uno de los mejores.\n",
        "   - Implementar técnicas de `data augmentation` textual para mejorar la robustez del modelo sin más datos. Estoy investigando sobre esto y se ve muy interesante aunque aun no lo termino de entender.\n",
        "\n",
        "## Reflexión final\n",
        "\n",
        "Este trabajo muestra que entender el contexto técnico y lingüístico de los modelos es clave. No basta con aplicar técnicas: hay que adaptarlas al dominio y al objetivo. El éxito del modelo no solo se mide en métricas, sino en su alineación con la lógica del problema y su capacidad para generalizar. La práctica ha permitido consolidar conocimientos sobre NLP, modelado supervisado y análisis crítico de resultados. También entiendo el esfuerzo descomunal e importante que tiene el el analisis de exploración y prepocesamiento.\n"
      ],
      "metadata": {
        "id": "8aX9sRaV-eYn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4zDUFW7EPNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}